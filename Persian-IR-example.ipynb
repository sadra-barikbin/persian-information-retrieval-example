{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadra-barikbin/persian-information-retrieval-example/blob/unify-all-methods/Persian-IR-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "innovative-letter",
      "metadata": {
        "id": "innovative-letter"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S6JCv2ZVCX4u",
      "metadata": {
        "id": "S6JCv2ZVCX4u"
      },
      "outputs": [],
      "source": [
        "!pip install hazm transformers ir_measures\n",
        "!pip install -q clean-text[gpl]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da59081d",
      "metadata": {
        "id": "da59081d"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    ابتدا کتاب‌خانه‌های لازم را فرا می‌خوانیم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "civic-birth",
      "metadata": {
        "id": "civic-birth"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import yaml\n",
        "import hazm\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ir_measures as IRm\n",
        "import tensorflow\n",
        "import itertools\n",
        "from torch.data.utils import DataLoader,IterableDataset\n",
        "from typing import List, Tuple, Union\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import make_scorer, average_precision_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig, AutoTokenizer, AutoModel, TFAutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "URH-AirBjcrL",
      "metadata": {
        "id": "URH-AirBjcrL"
      },
      "source": [
        "# Loading & Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cWjISsLTPtqw",
      "metadata": {
        "id": "cWjISsLTPtqw"
      },
      "source": [
        "## Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cX9FwdFUjfkj",
      "metadata": {
        "id": "cX9FwdFUjfkj"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/language-ml/2-LM-embedding-projects/raw/main/problem3/doc_collection.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AHXJRwbKk8mK",
      "metadata": {
        "id": "AHXJRwbKk8mK"
      },
      "outputs": [],
      "source": [
        "!unzip doc_collection.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9YX2f4_plKLa",
      "metadata": {
        "id": "9YX2f4_plKLa"
      },
      "outputs": [],
      "source": [
        "!cat IR_dataset/1000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4e5bda",
      "metadata": {
        "id": "3a4e5bda"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    در این بخش مجموعه دادگان دانلود و استخراج می‌شود و سپس از روی آن\n",
        "    Corpus\n",
        "    برای ساخت مدل‌های زبانی ایجاد می‌کنیم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yr2uuva8lt2R",
      "metadata": {
        "id": "Yr2uuva8lt2R"
      },
      "outputs": [],
      "source": [
        "# corpus = [(int(path.stem), path.open().read()) for path in Path('dataset/IR_dataset').iterdir()]\n",
        "corpus = [(int(path.stem), path.open().read()) for path in Path('dataset/IR_dataset').iterdir()]\n",
        "corpus = pd.DataFrame(corpus, columns=['docId','text']).set_index('docId').sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hXmMh6rU2rfi",
      "metadata": {
        "id": "hXmMh6rU2rfi"
      },
      "outputs": [],
      "source": [
        "ccorpus = [(int(path.stem), path.open().read()) for path in Path('IR_dataset').iterdir()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "em6lACkLggoq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "em6lACkLggoq",
        "outputId": "b0b330b3-bb87-4576-e722-8ce792f49af9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>docId</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>برخی از هواداران مصدق یا اعضای جبهه ملی که در ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>جبهه ملی ایران که به اختصار جبهه ملی نیز خواند...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>سرلشکر زاهدی در سال ۱۳۲۸ و پس از آن‌که دخالت‌ه...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>نمایندگان طرفدار مصدق در حمایت از ابقای دولت و...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>نمایندگان طرفدار مصدق در حمایت از ابقای دولت و...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text\n",
              "docId                                                   \n",
              "0      برخی از هواداران مصدق یا اعضای جبهه ملی که در ...\n",
              "1      جبهه ملی ایران که به اختصار جبهه ملی نیز خواند...\n",
              "2      سرلشکر زاهدی در سال ۱۳۲۸ و پس از آن‌که دخالت‌ه...\n",
              "3      نمایندگان طرفدار مصدق در حمایت از ابقای دولت و...\n",
              "4      نمایندگان طرفدار مصدق در حمایت از ابقای دولت و..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YovdZ4crPwmk",
      "metadata": {
        "id": "YovdZ4crPwmk"
      },
      "source": [
        "## Qrels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf04241b",
      "metadata": {
        "id": "cf04241b"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    در این بخش فایل کوئری‌ها را دانلود می‌کنیم و از روی فایل آن دیتافریمی می‌سازیم که کوئری و داک بازیابی شده با سطح نزدیکی را نمایش دهد\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qxLS7matqWct",
      "metadata": {
        "id": "qxLS7matqWct"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/language-ml/2-LM-embedding-projects/main/problem3/evaluation_IR.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OMzUU5mVqHSg",
      "metadata": {
        "id": "OMzUU5mVqHSg"
      },
      "outputs": [],
      "source": [
        "# query_raw_data = yaml.safe_load(open('evaluation_IR.yml'))\n",
        "query_raw_data = yaml.safe_load(open('dataset/evaluation_IR.yml'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fMhrz0biMTn1",
      "metadata": {
        "id": "fMhrz0biMTn1"
      },
      "outputs": [],
      "source": [
        "query = pd.Series(query_raw_data.keys())\n",
        "qrels = [{'query_id':idx, 'doc_id':d,\n",
        "          'relevance':3} for idx,q in query.to_dict().items() for d in query_raw_data[q]['similar_high']]\n",
        "qrels.extend([{'query_id':idx, 'doc_id':d,\n",
        "          'relevance':2} for idx,q in query.to_dict().items() for d in query_raw_data[q]['similar_med']])\n",
        "qrels.extend([{'query_id':idx, 'doc_id':d,\n",
        "          'relevance':1} for idx,q in query.to_dict().items() for d in query_raw_data[q]['similar_low']])\n",
        "qrels.extend([{'query_id':idx, 'doc_id':query_raw_data[q]['relevant'][0],\n",
        "          'relevance':4} for idx,q in query.to_dict().items()])\n",
        "qrels = pd.DataFrame(qrels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y4TNJYGzE1zp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4TNJYGzE1zp",
        "outputId": "c71c26e4-7f4b-4661-e7df-71e7579d3562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('گرجستان  تاریخ',\n",
              " {'relevant': [388],\n",
              "  'similar_high': [389, 390, 391, 392, 393, 394],\n",
              "  'similar_low': [404, 405, 406, 407, 408, 409, 410, 411, 412, 413],\n",
              "  'similar_med': [395, 364, 396, 397, 398, 399, 400, 401, 402, 403]})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query[147],query_raw_data[query[147]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5vr0k3fLgz5J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5vr0k3fLgz5J",
        "outputId": "2b52a332-4084-43fa-c2f3-decbbee3af76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>doc_id</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>464</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>129</td>\n",
              "      <td>1083</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>122</td>\n",
              "      <td>2137</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>2613</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>119</td>\n",
              "      <td>617</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   query_id  doc_id  relevance\n",
              "0       126     464          2\n",
              "1       129    1083          2\n",
              "2       122    2137          3\n",
              "3        48    2613          2\n",
              "4       119     617          1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qrels.sample(n=5).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F8KJ3p-mnoht",
      "metadata": {
        "id": "F8KJ3p-mnoht"
      },
      "source": [
        "## Normaliztion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e6bb5b9",
      "metadata": {
        "id": "9e6bb5b9"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    با استفاده از نرمال‌ساز کتابخانه هضم، فایل‌های خود را نرمال می‌کنیم که در فرآیند ساخت مدل زبانی بهتر عمل کنیم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BjpC37pvg9Rz",
      "metadata": {
        "id": "BjpC37pvg9Rz"
      },
      "outputs": [],
      "source": [
        "normalize = hazm.Normalizer().normalize\n",
        "corpus.text = corpus.text.transform(normalize)\n",
        "query = query.transform(normalize)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_IEs3O0emcKQ",
      "metadata": {
        "id": "_IEs3O0emcKQ"
      },
      "source": [
        "# Embedding the documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dS2qRcj5mmvL",
      "metadata": {
        "id": "dS2qRcj5mmvL"
      },
      "source": [
        "## Method 1 : Tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b22ceba",
      "metadata": {
        "id": "7b22ceba"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    برای ساخت بردارها بر اساس\n",
        "    Tf-Idf\n",
        "    از کتاب‌خانه\n",
        "    sklearn\n",
        "    استفاده می‌کنیم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0x8lSOD-mp53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x8lSOD-mp53",
        "outputId": "006df6d9-f3f7-4ac5-ae1e-ea3441198fbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_features=500, ngram_range=(1, 2))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=500,ngram_range=(1,2))\n",
        "vectorizer.fit(corpus.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vwbPf8qxJ_p9",
      "metadata": {
        "id": "vwbPf8qxJ_p9"
      },
      "source": [
        "## Method 2 : ParsBert"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8270ad4a",
      "metadata": {
        "id": "8270ad4a"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    برای استفاده از برت، از\n",
        "    ParsBert\n",
        "    استفاده می‌کنیم.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertVectorizer(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    self.model = AutoModel.from_pretrained(\"HooshvareLab/bert-fa-zwnj-base\", from_tf = True).cuda()\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-zwnj-base\")\n",
        "    self.model.eval()\n",
        "    self.fitted = False\n",
        "  def get_embed(self, X: Union[List[str],pd.Series]):\n",
        "    result = torch.empty((0,768))\n",
        "    for batch in DataLoader(IterableDataset(X),batch_size=128,shuffle=False):\n",
        "      encoding = tokenizer.encode_plus(batch,add_special_tokens=True,return_token_type_ids=False,max_length = 500,\n",
        "                                       truncation=True,return_attention_mask=True,return_tensors='pt')\n",
        "      encoding = {k:v.cuda() for k,v in encoding.items()}\n",
        "      with torch.no_grad():\n",
        "        out = self.model(**encoding)\n",
        "      result = torch.cat(result, out['pooler_output'].cpu())\n",
        "    return result.numpy()\n",
        "  def fit(self,X: Union[List[str],pd.Series]):\n",
        "    if self.fitted:\n",
        "      return\n",
        "    doc_vec = np.empty((0, 768))\n",
        "    doc_map = np.empty(0)\n",
        "    tokenizer = hazm.WordTokenizer(replace_numbers=True)\n",
        "    subdocs = []\n",
        "    subdoc_doc_idx = []\n",
        "    for index, doc in tqdm.tqdm(X):\n",
        "      doc_split = tokenizer.tokenize(doc)\n",
        "      doc_parts = [' '.join(doc_split[i:i + 300]) for i in range(0, len(doc_split) - 150, 150)]\n",
        "      subdocs.extend(doc_parts)\n",
        "      subdoc_doc_idx.extend([index] * len(doc_parts))\n",
        "    \n",
        "      for part in doc_parts:\n",
        "        doc_vec = np.append(doc_vec, get_embed(part), axis = 0)\n",
        "        doc_map = np.append(doc_map, index)\n",
        "    self.vectors = result\n",
        "    self.fitted = True\n",
        "  def transform(self, X)\n"
      ],
      "metadata": {
        "id": "jpqyqL7cJGok"
      },
      "id": "jpqyqL7cJGok",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wwgVFEvLwGf2",
      "metadata": {
        "id": "wwgVFEvLwGf2"
      },
      "outputs": [],
      "source": [
        "text = \"ما در قرن ۲۱ زندگی می‌کنیم\" \n",
        "encoding = tokenizer.encode_plus(\n",
        "      text,\n",
        "      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "      return_token_type_ids=False,\n",
        "      max_length = 500,\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',  # Return PyTorch tensors\n",
        "    )\n",
        "out = model(\n",
        "            input_ids = encoding['input_ids'].cuda(), \n",
        "            attention_mask= encoding['attention_mask'].cuda())\n",
        "out['pooler_output'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1876c19",
      "metadata": {
        "id": "f1876c19"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    ابتدا تنظیمات لازم را برای استفاده از مدل از پیش آموزش داده شده تنظیم می‌کنیم.\n",
        "    سپس از آنجا که طول داک‌ها بعضا بیشتر از ۵۰۰ کلمه هستند،\n",
        "    هر فایل را به پنجره‌های ۳۰۰ کلمه‌ای تقسیم می‌کنیم،\n",
        "    به طوری که هر کلمه در دو پنجره ظاهر شود و با این کار برای هر فایل ممکن است چند بردار تولید شود\n",
        "    نهایتا نزدیک‌ترین بردار آن به کوئری را به عنوان پاسخ آن در نظر می‌گیریم؛\n",
        "    اما گویا به طور کلی از برت برای داده‌های بزرگ استفاده نمی‌شود\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0CJT2mJ3-OuZ",
      "metadata": {
        "id": "0CJT2mJ3-OuZ"
      },
      "outputs": [],
      "source": [
        "def get_embed(part):\n",
        "  encoding = tokenizer.encode_plus(\n",
        "    part,\n",
        "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "    return_token_type_ids=False,\n",
        "    max_length = 500,\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',  # Return PyTorch tensors\n",
        "  )\n",
        "  encoding = {k:v.cuda() for k,v in encoding.items()}\n",
        "  with torch.no_grad():\n",
        "    out = model(**encoding)\n",
        "  return out['pooler_output'].cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w1yGQuFmwc9R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1yGQuFmwc9R",
        "outputId": "a0ee3187-edd8-495d-8be8-397e9a739247",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3258it [06:04,  8.95it/s]\n"
          ]
        }
      ],
      "source": [
        "doc_vec = np.empty((0, 768))\n",
        "doc_map = np.empty(0)\n",
        "tokenizer = hazm.WordTokenizer(replace_numbers=True)\n",
        "for index, doc in tqdm.tqdm(corpus.iterrows()):\n",
        "  doc_split = tokenizer.tokenize(doc['text'])\n",
        "  doc_parts = [' '.join(doc_split[i:i + 300]) for i in range(0, len(doc_split) - 150, 150)]\n",
        "  for part in doc_parts:\n",
        "    doc_vec = np.append(doc_vec, get_embed(part), axis = 0)\n",
        "    doc_map = np.append(doc_map, index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa36e63",
      "metadata": {
        "id": "daa36e63"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    پیاده‌سازی روش سوم که\n",
        "    tf-idf\n",
        "    وزن‌دار برحسب\n",
        "    pos-tag\n",
        "    هاست در نوتبوکی رو فولدر\n",
        "    method-3\n",
        "    آمده‌است\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vB7lcQxsoZZy",
      "metadata": {
        "id": "vB7lcQxsoZZy"
      },
      "source": [
        "# Document Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf79bdf",
      "metadata": {
        "id": "dbf79bdf"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    با استفاده از تابع نزدیک‌ترین همسایه‌ها در\n",
        "    sklearn\n",
        "    کلاسی برای اجرای الگوریتم\n",
        "    KNN\n",
        "    می‌سازیم که داک‌ها را\n",
        "    fit\n",
        "    کند و داک‌های نزدیک کوئری را حدس بزند.\n",
        "    برای هر دو روش برت و\n",
        "    tf-idf\n",
        "    از\n",
        "    knn\n",
        "    استفاده می‌کنیم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fu0yYIIrLbpX",
      "metadata": {
        "id": "Fu0yYIIrLbpX"
      },
      "outputs": [],
      "source": [
        "class KNN_based_IR(BaseEstimator):\n",
        "  def __init__(self,sampleIdx_docId_map=None, n_neighbors=1+10+10+10) -> None:\n",
        "    self.sampleIdx_docId_map = sampleIdx_docId_map\n",
        "    self.n_neighbors = n_neighbors\n",
        "    self.nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
        "  def set_params(self,**kwargs):\n",
        "    self.nn.set_params(**kwargs)\n",
        "  def fit(self, X: np.array):\n",
        "    self.nn.fit(X)\n",
        "  def predict(self, X: np.array):\n",
        "    distances, sampleIndices = self.nn.kneighbors(X, n_neighbors=self.n_neighbors)\n",
        "    scores = np.max(distances)-distances\n",
        "    if not self.sampleIdx_docId_map:\n",
        "      docIds = sampleIndices\n",
        "    else:\n",
        "      docIds = np.array([self.sampleIdx_docId_map[idx] for idx in sampleIndices.flatten()]).reshape(sampleIndices.shape)\n",
        "      _scores = []\n",
        "      _docIds = []\n",
        "      for i in range(docIds.shape[0]):\n",
        "        docs_of_query = docIds[i]\n",
        "        _docIds.append(list(dict(zip(docs_of_query, np.empty(len(docs_of_query)))).keys()))\n",
        "        doc_score_dict = {}\n",
        "        for j in range(len(docs_of_query)):\n",
        "          docId = docs_of_query[j]\n",
        "          if docId in doc_score_dict:\n",
        "            continue\n",
        "          else:\n",
        "            doc_score_dict[docId] = scores[i][j]\n",
        "        _scores.append(list([score for doc,score in doc_score_dict.items()))\n",
        "      docIds = _docIds\n",
        "      scores = _scores\n",
        "    return scores, docIds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cSu5M10thrcN",
      "metadata": {
        "id": "cSu5M10thrcN"
      },
      "outputs": [],
      "source": [
        "IR_system = KNN_based_IR()\n",
        "IR_system.fit(vectorizer.transform(corpus.text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dQucB5SN2s9-",
      "metadata": {
        "id": "dQucB5SN2s9-"
      },
      "outputs": [],
      "source": [
        "bert_knn = KNN_based_IR(n_neighbors=80)\n",
        "bert_knn.fit(doc_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9FD5slp-hsik",
      "metadata": {
        "id": "9FD5slp-hsik"
      },
      "source": [
        "# IR Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MmLtge7sy__H",
      "metadata": {
        "id": "MmLtge7sy__H"
      },
      "outputs": [],
      "source": [
        "def tf_knn_pred(knn):\n",
        "  return knn.predict(vectorizer.transform(query))\n",
        "\n",
        "\n",
        "preds = tf_knn_pred(IR_system)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63025700",
      "metadata": {
        "id": "63025700"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    برای تخمین برت برحسب\n",
        "    knn\n",
        "    باید تعداد بیشتری بردار نزدیک را به دست بیاوریم و بردارهای مربوط به یک داک یکسان را از روی آن حذف کنیم\n",
        "    و فقط نزدیک‌ترین را باقی بگذاریم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IGEslI50bUEf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "IGEslI50bUEf",
        "outputId": "a9899c07-756a-44e0-e7d4-6fed35600ac0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:06<00:00, 24.19it/s]\n"
          ]
        }
      ],
      "source": [
        "def bert_knn_pred(knn):\n",
        "  bert_score = []\n",
        "  bert_id = []\n",
        "  mn = 100\n",
        "  for q in tqdm.tqdm(query):\n",
        "    score, oid = knn.predict(get_embed(q))\n",
        "    score = score[0]\n",
        "    doc_id = [doc_map[i] for i in oid[0]]\n",
        "    n_score = []\n",
        "    n_id = []\n",
        "    for sc, id in zip(score, doc_id):\n",
        "      if id not in n_id:\n",
        "        n_id.append(id)\n",
        "        n_score.append(sc)\n",
        "    mn = min(mn, len(n_score[:31]))\n",
        "    bert_score.append(n_score[:31])\n",
        "    bert_id.append(n_id[:31])\n",
        "  \n",
        "  return (np.array(bert_score), np.array(bert_id).astype(int))\n",
        "\n",
        "\n",
        "bert_pred = bert_knn_pred(bert_knn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iSK68yffPg8-",
      "metadata": {
        "id": "iSK68yffPg8-"
      },
      "source": [
        "## Adapting IR output to our Test Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969a1ca5",
      "metadata": {
        "id": "969a1ca5"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    از تابع زیر برای اینکه بتوانیم خروجی بازیابی را تبدیل به حالتی برای ارزیابی کوئری‌ها بکنیم استفاده می‌کنیم.\n",
        "    ما برای اینکه بتوانیم خروجی\n",
        "    knn\n",
        "    را تقریبا نزدیک به خروجی کوئری‌ها کنیم، تقریب زدیم که غیر از داک اصلی،\n",
        "    از هر سطح نزدیکی به طور میانگین ۱۰ داک بازیابی می‌شود و با استفاده از آن ملاک‌ها را اندازه می گیریم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jDaNxlfrPovG",
      "metadata": {
        "id": "jDaNxlfrPovG"
      },
      "outputs": [],
      "source": [
        "def adapt_IR_output_to_measure_input(IR_output: Tuple[Union[np.array,List[List[float]]], Union[np.array,List[List[int]]]]):\n",
        "  scores, docIds = IR_output\n",
        "  if type(docIds) == list:\n",
        "    return pd.DataFrame({'query_id': list(itertools.chain(*[[query.index[i]]*len(docIds[i]) for i in range(len(query.index))])).astype(str),\n",
        "                       'doc_id':   list(itertools.chain(*docIds)).astype(str),\n",
        "                       'score':    list(itertools.chain(*scores))})\n",
        "  else:\n",
        "    return pd.DataFrame({'query_id': np.tile(query.index,(31,1)).flatten(order='F').astype(str),\n",
        "                       'doc_id':   docIds.flatten().astype(str),\n",
        "                       'score':    scores.flatten()})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "936edd54",
      "metadata": {
        "id": "936edd54"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    این تابع نیز برای بهبود عملکرد\n",
        "    knn\n",
        "    ایجاد شده است تا با تغییر متریک آن بتوانیم بازیابی بهتری با توجه به ملاک‌های ارزیابی داشته باشیم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dIBggEIjOGJ5",
      "metadata": {
        "id": "dIBggEIjOGJ5"
      },
      "outputs": [],
      "source": [
        "def knn_tuning(k, param, embed, pred_f, measure):\n",
        "  score = -1\n",
        "  best_p = -1\n",
        "  for p in param:\n",
        "    knn = KNN_based_IR(n_neighbors=k)\n",
        "    knn.set_params(metric = p)\n",
        "    knn.fit(embed)\n",
        "    val = measure(qrels.astype({'query_id':str,'doc_id':str}),pred_f(knn))\n",
        "    if val > score:\n",
        "      score = val\n",
        "      best_p = p\n",
        "  return best_p, score\n",
        "\n",
        "\n",
        "param = ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', 'manhattan'] # Metrics for sparse input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oYNQ3qYThxZ_",
      "metadata": {
        "id": "oYNQ3qYThxZ_"
      },
      "source": [
        "## MRR (Mean Reciprocal Rank)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9411db02",
      "metadata": {
        "id": "9411db02"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    برای استفاده از این اندازه‌گیری، باید محل مرتبط‌ترین داک هر کوئری را بین لیست داک‌های بازیابی شده بیابیم و معکوس آن را حساب کنیم و سپس میانگین بگیریم.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1tXZutKIhv7V",
      "metadata": {
        "id": "1tXZutKIhv7V"
      },
      "outputs": [],
      "source": [
        "MRR = IRm.measures.MRR()\n",
        "def mrr_measure(qrels, ret):\n",
        "  ret = adapt_IR_output_to_measure_input(ret)\n",
        "  return MRR.calc_aggregate(qrels[qrels.relevance == 4], ret)\n",
        "# mrr_scorer = make_scorer(mrr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KokouE3mi5X7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KokouE3mi5X7",
        "outputId": "b5d32932-d27c-485e-a6f1-5a0f43277969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.11047063325391496"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mrr_measure(qrels.astype({'query_id':str,'doc_id':str}),preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n7IwsjeKS2w1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7IwsjeKS2w1",
        "outputId": "ed9bf154-c592-4077-807d-eee6310995c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('cosine', 0.11664736491005835)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_tuning(31, param, vectorizer.transform(corpus.text), tf_knn_pred, mrr_measure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xXg9mfejzGIe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXg9mfejzGIe",
        "outputId": "3b3f9e63-cf56-482b-c688-b138dd11956f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.06931617823372208"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mrr_measure(qrels.astype({'query_id':str,'doc_id':str}),bert_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd3e60b-5e15-4d66-8673-e4e36b685241",
      "metadata": {
        "id": "cdd3e60b-5e15-4d66-8673-e4e36b685241",
        "outputId": "94e3a54c-b011-451d-b4f7-bcc3846dc36a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:05<00:00, 25.60it/s]\n",
            "100%|██████████| 150/150 [00:11<00:00, 12.60it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 25.01it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 26.23it/s]\n",
            "100%|██████████| 150/150 [00:06<00:00, 24.50it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 25.57it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('cosine', 0.06982707206877474)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_tuning(80, param, doc_vec[1:], bert_knn_pred, mrr_measure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rFbJ5vp_lXeA",
      "metadata": {
        "id": "rFbJ5vp_lXeA"
      },
      "source": [
        "## MAP (Mean Average Precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J4z0Ti8eldAH",
      "metadata": {
        "id": "J4z0Ti8eldAH"
      },
      "outputs": [],
      "source": [
        "def map_measure(qrels, ret):\n",
        "  ret = adapt_IR_output_to_measure_input(ret)\n",
        "  return np.mean([IRm.measures.AP(rel=level).\\\n",
        "                    calc_aggregate(qrels[qrels.relevance == level], ret) for level in range(1,4+1)])\n",
        "\n",
        "# map_scorer = make_scorer(map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dkp5CLB8jB2O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkp5CLB8jB2O",
        "outputId": "c2055741-e782-4636-8672-dcf94f804f05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.06630537139767945"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "map_measure(qrels.astype({'query_id':str,'doc_id':str}),preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5CXrnzUbVD4A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CXrnzUbVD4A",
        "outputId": "f25e4e20-7b5b-4aa9-dca6-aa52ed3129a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('cosine', 0.06931719832816999)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_tuning(31, param, vectorizer.transform(corpus.text), tf_knn_pred, map_measure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z454fP2tzMiw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z454fP2tzMiw",
        "outputId": "0dc6c753-4138-42ae-93f5-4318b2e54fdf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.048315030270106925"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "map_measure(qrels.astype({'query_id':str,'doc_id':str}),bert_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78880f20-5751-4754-8976-5339f384f4ef",
      "metadata": {
        "id": "78880f20-5751-4754-8976-5339f384f4ef",
        "outputId": "70db9a55-c5df-4f6c-8c3d-f5ee1dbadcff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:06<00:00, 24.61it/s]\n",
            "100%|██████████| 150/150 [00:11<00:00, 13.24it/s]\n",
            "100%|██████████| 150/150 [00:06<00:00, 24.08it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 25.18it/s]\n",
            "100%|██████████| 150/150 [00:06<00:00, 24.42it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 25.91it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('cityblock', 0.04838834768432319)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_tuning(80, param, doc_vec[1:], bert_knn_pred, map_measure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xbhSNyvo19ja",
      "metadata": {
        "id": "xbhSNyvo19ja"
      },
      "source": [
        "## P@K"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "034427d4",
      "metadata": {
        "id": "034427d4"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    با توجه به اینکه در کوئری‌ها ما رنکینگ نداریم، برای محاسبه این معیار\n",
        "    precision\n",
        "    را در\n",
        "    i\n",
        "    دسته اول حساب می‌کنیم و سپس میانگین آن‌ها را برمی‌گردانیم\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8IRhcs4H19NU",
      "metadata": {
        "id": "8IRhcs4H19NU"
      },
      "outputs": [],
      "source": [
        "def p_measure(qrels, ret):\n",
        "  ret = adapt_IR_output_to_measure_input(ret)\n",
        "  return np.mean([IRm.measures.P(cutoff=k, rel=level).\\\n",
        "                    calc_aggregate(qrels[qrels.relevance == level], ret)\\\n",
        "                  for k,level in zip([1,11,21,31],range(1,4+1))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A4s1-EdTjd52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4s1-EdTjd52",
        "outputId": "78b91910-1fc8-40f7-c9c2-4bcba51e3468"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.033872596937113045"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_measure(qrels.astype({'query_id':str,'doc_id':str}),preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5JS9sRhmVOXm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JS9sRhmVOXm",
        "outputId": "f535e4ff-ec89-4171-d1ca-c293c1d4171a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('cosine', 0.03418284224735836)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_tuning(31, param, vectorizer.transform(corpus.text), tf_knn_pred, p_measure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ITU8eJ6wzQcz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITU8eJ6wzQcz",
        "outputId": "0150aac5-b08e-4be2-84be-910a080fd6a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.026597076758367057"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p_measure(qrels.astype({'query_id':str,'doc_id':str}),bert_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ec0d85-22ec-4f25-a826-602d5a5a50e3",
      "metadata": {
        "id": "53ec0d85-22ec-4f25-a826-602d5a5a50e3",
        "outputId": "dc97a1e9-638e-442c-e1d4-60e0a579e352"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:06<00:00, 24.51it/s]\n",
            "100%|██████████| 150/150 [00:11<00:00, 12.68it/s]\n",
            "100%|██████████| 150/150 [00:06<00:00, 24.47it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 25.32it/s]\n",
            "100%|██████████| 150/150 [00:06<00:00, 24.64it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 26.06it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('cosine', 0.02688893543732251)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_tuning(80, param, doc_vec[1:], bert_knn_pred, p_measure)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "434057fc",
      "metadata": {
        "id": "434057fc"
      },
      "source": [
        "<div dir='rtl'>\n",
        "    بنظر می‌رسد\n",
        "    tuning\n",
        "    های انجام شده تغییر ناچیزی در امتیازهای ما داشته‌اند و نتیجه را بهبود چندانی نداده‌اند\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-t-lIUk3Mi3i",
      "metadata": {
        "id": "-t-lIUk3Mi3i"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'embedding': [bert_vectorizer,tfidf_vectorizer],\n",
        "    ''\n",
        "}"
      ],
      "metadata": {
        "id": "qQZKSv6wS7N7"
      },
      "id": "qQZKSv6wS7N7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wOsckUZxMlOq",
      "metadata": {
        "id": "wOsckUZxMlOq"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([('embedding','passthrough'),\n",
        "                     ('retrieval','passthrough')])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Persian-IR-example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}