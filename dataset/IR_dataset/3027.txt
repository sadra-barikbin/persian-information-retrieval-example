پیچیدگی مدل‌های پارامتری با تعداد پارامترهای مدل و مقادیر آن‌ها سنجیده می‌شود. هرچه این پیچیدگی بیشتر باشد خطر بیش‌برازش برای مدل بیشتر است. پدیدهٔ بیش‌برازش زمانی رخ می‌دهد که مدل به‌جای یادگیری الگوهای موجود در داده، خود داده را به خاطر می‌سپارد. در این حالت، مدل برای آن مجموعه دادهٔ به‌خصوص خوب عمل می‌کند اما برای داده‌های مشابه دیگر عملکرد خوبی ندارد، که یعنی عمل یادگیری به خوبی انجام نشده‌است. برای جلوگیری از بیش‌برازش در مدل‌های خطی مانند رگرسیون خطی یا رگرسیون لجستیک، یک «جریمه» به تابع هزینه اضافه می‌شود تا از افزایش زیاد پارامترها جلوگیری شود. به این کار تنظیم مدل گفته می‌شود. دو راه متداول تنظیم مدل‌های خطی روش‌های formula_2 و formula_1 هستند. در روش formula_2 ضریبی از نُرمِ formula_2 به تابع هزینه اضافه می‌شود و در روش formula_1 ضریبی از نُرمِ formula_1 که همان نُرمِ اقلیدسی است به تابع هزینهٔ اضافه می‌شود. نام روش‌های formula_2 و formula_1 از نُرمی که در این روش‌ها به تابع هزینه اضافه می‌شود گرفته شده‌است.

در تنظیم مدل به روش formula_2 تابع هزینه را به این شکل تغییر می‌دهیم:

formula_126

این روش تنظیم مدل که به روش لَسو نیز شهرت دارد باعث می‌شود که بسیاری از پارامترهای مدل نهائی صفر شوند و مدل به اصلاح خلوت شود.

در تنظیم مدل به روش formula_1 که به رگرسیون ستیغی نیز شهرت دارد تابع هزینه را به این شکل تغییر می‌دهیم:

formula_128

در روش تنظیم از طریق formula_1 سعی می‌شود طول اقلیدسی بردار formula_130 کوتاه نگه داشته شود. formula_131 در هر دو روش formula_2 و formula_1 یک عدد مثبت است که میزان تنظیم مدل را معین می‌کند. هرچقدر formula_131کوچکتر باشد جریمهٔ کمتری برای بزرگی نرم بردار پارامترها یعنی formula_56 محاسبه می‌شود. مقدار بهینهٔ formula_131 از طریق آزمایش بر روی بخشی از داده‌ها پیدا می‌شود که در یادگیری مدل دخالت داده نشده‌اند؛ به این بخش از داده‌ها، دادهٔ اعتبار یا مجموعهٔ اعتبارسنجی گفته می‌شود.

با استفاده از ضرایب لاگرانژ می‌توان اثبات کرد که تنظیم مدل formula_2 و formula_1 نوعی بهینه‌سازی مقید هستند. در تنظیم مدل formula_2 تابع هزینه به نحوی کمینه می‌شود که نرمِ formula_2 از یک مقدار مشخصی که بستگی به formula_131 دارد بیشتر نشود. به همین نحو، تنظیم مدل formula_1 تابع هزینه را همزمان با مقید کردن نرم formula_1 کاهش می‌دهد.