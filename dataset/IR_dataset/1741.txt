=
اگر توزیع احتمال "formula_4" در یک تابع چگالی احتمال "formula_53"، صدق کند پس می‌توان مقدار مورد انتظار را به صورت زیر محاسبه کرد:

: formula_54

تعریف عمومی
عموماً اگر "X"یک متغیر تصادفی تعریف شده روی یک فضای احتمال , باشد پس مقدار مورد انتظار X (که به صورت E["X"], , <span style="text-decoration:overline">"X"</span> or E["X"], مشخص می‌شود) به صورت انتگرال لبسگو تعریف می‌شود:

:formula_55

وقتی که این انتگرال وجود داشته باشد، پس به صورت امید "X" تعریف می‌شود. توجه کنید که هیچ متغیر تصادفی اصلاً مقدار مورد انتظار متناهی ندارد چون ممکن نیست که این انتگرال مطلقاً همگرا باشد؛ بعلاوه برای بعضی این اصلاً تعریف نشده‌است (مثلاً توزیع کوشی). دو متغیر با توزیع احتمال یکسان، مقدار مورد انتظار یکسانی خواهند داشت در صورتی که این انتگرال تعریف شده باشد
این موضوع مستقیماً از تعریف حالت گسسته پیروی می‌کند که اگر "X"یک متغیر تصادفی ثابت باشد (یعنی برای چند تا مقدار حقیقی ثابت "b") پس مقدار مورد انتظار"X" نیز "b"خواهد بود.
مقدار مورد انتظار یک تابع دلخواه ("X", "g"("X", نسبت به تابع چگالی احتمال ("ƒ"("x" از طریق ضرب داخلی "ƒ" و "g" بدست می‌آید.

:formula_56

بعضی مواقع به این قانون آماری ناخودآگاه می‌گویند. بااستفاده از نمایش‌ها به صورت انتگرال ریمان – استیلتجس و انتگرال‌گیری جزئی می‌توان این فرمول را به صورت زیر دوباره بیان کرد:

* formula_57 if formula_58,
* formula_59 if formula_60.

چون در این حالت ویژه، α یک عدد حقیقی مثبت را نشان می‌دهد پس:

:formula_61

به ویژه برای α = ۱ این به شکل زیر کاهش می‌یابد در صورتی که , باشد (که F تابع توزیع تجمعی X است).
اصطلاحات متداول
* وقتی که شخصی از قیمت مورد انتظار، ارتفاع مورد انتظار و غیره صحبت می‌کند یعنی اینکه مقدار مورد انتظار یک متغیر تصادفی آن یک قیمت یا یک ارتفاع و غیره است.
* وقتی که شخصی از تعداد مورد انتظار تلاش‌های مورد نیاز برای موفق شدن صحبت می‌کند، ممکن است شخص به‌طور محافظه کارانه آن را به صورت نسبت معکوس احتمال موفقیت برای اینچنین تلاشی تقریب بزند (یعنی مقدار مورد انتظار توزیع هندسی).
ویژگی‌ها
ثابت‌ها
مقدار مورد انتظار یک ثابت مساوی باخود ثابت است یعنی اگر "c"یک ثابت است پس است.

یکنوایی
اگر "X" و"Y "متغیرهای تصادفی هستند به طوریکه است، پس .

خطی بودن
عملگر مقدار مورد انتظار (یا عملگر امید ریاضی) E در مورد زیر خطی است:

:formula_17
:formula_18
:formula_19

توجه داشته باشید که نتیجهٔ دوم حتی اگر "X" از لحاظ آماری مستقل از "Y" نباشد، معتبر و دست است. با ترکیب نتایج حاصل از سه معادلهٔ قبلی، ما می‌توانیم به نتیجهٔ زیر برسیم:

:formula_20
:formula_21

برای هر کدام از متغیرهای تصادفی "X"و "Y" (که باید در همان فضای احتمال تعریف شوند) و هر عدد formula_14و formula_15نتیجهٔ بالا در نظر گرفته می‌شود.
امید ریاضی مکرر
امید ریاضی برای متغیرهای تصادفی گسسته
برای هر کدام از متغیرهای تصافی گسستهٔ "X", "Y" ما ممکن است امید ریاضی شرطی را تعریف کنیم:

:formula_69

که بدین معنی است E["X"|"Y"]("y") یک تابع"Y" است.
پس امید ریاضی "x "در معادلهٔ زیر صدق می‌کند:

:formula_70

:::formula_71

:::formula_72

:::formula_73

:::formula_74

:::formula_75

:::formula_76

:::formula_77

:::formula_78

بنابر این معادلهٔ زیر برقرار است:

:formula_79

یعنی:

:formula_80

طرف راست معادله به امید ریاضی مکرر اشاره دارد و گاهی اوقات قانون برج یا احتمال برج نامیده شده‌است.
این پیش فرض در قانون کل امید ریاضی مورد توجه قرار گرفته‌است.
امید مکرر برای متغیرهای تصادفی پیوسته
در مورد متغیرهای پیوسته، نتایج ما کاملاً قابل قیاس هستند. تعریف امید ریاضی شرطی از نابرابری‌ها، تابع‌های چگالی و انتگرال‌ها استفاده می‌کند تا با نابرابری‌ها، تابع‌های جزئی و مجموع‌ها به ترتیب جایگزین کند. اما نتیجهٔ اصلی هنوز برقرار است:

:formula_79

نابرابری‌ها
اگر یک متغیر تصادفی "x" همیشه کمتر یا مساوی با متغیر تصادفی دیگری "Y" باشد، پس امید ریاضی (یا مقدار مورد انتظار) کمتر یا مساوی با مقدار مورد انتظار "Y" است.
اگر , است، پس . است.
به ویژه، اگر y را با "X" منطبق کنیم، می‌دانیم و. است. از اینرو ما می‌دانیم و . با توجه به خطی بودن امید ریاضی ما می‌دانیم است. از اینرو، مقدار مطلق امید ریاضی یک متغیر تصادفی کمتر یا مساوی با مقدار مطلق آن است:

:formula_35

غیر ضربی
اگر تابع چگالی احتمال مشترک (یا توأم) "x "و" y "را در نظر بگیریم (مثلاً "j(x,y)") پس امید ریاضی "xy" بدین صورت است:

:formula_83

به‌طور کلی، عملگر مقدار مورد انتظار ضربی نیست، یعنی E["XY"] لزوماً با E["X"]·E["Y"] مساوی نیست. در حقیقت، مقداری که نمی‌تواند ضرب شود، را کوواریانس می‌نامند:

:formula_84

از اینرو، این ضرب هنگامیکه است، برقرار است، در آن کوواریانس، "X"و"Y" گفته می‌شود نا همبسته هستند (متغیرهای مستقل یک مورد مهم متغیرهای نا همبسته هستند).
حالا اگر "X" و "Y" مستقل هستند، پس با توجه به تعریف در اینجا" f" و" g "در واقع PDFهای حاشیه‌ای برای "X" و "Y"هستند. پس:

:formula_85

and .
مشاهده کنید که استقلال "X" و "Y" مورد نیاز است تا این معادله نوشته شود: , و این باید دومین تساوی بالا را ثابت کند. تساوی سوم از یک کاربرد اولیه و اصلی تئوری نوبینی-تونلی پیروی می‌کند.
ناوردایی تابعی
به‌طور کلی، عملگر امید ریاضی و تابع‌های متغیرهای تصادفی تبدیل نیم شوند یعنی:

:formula_86

یک نا تساوی مهم برای این موضوع نا تساوی جنسن است، که شامل مقدارهای مورد انتظار تابع‌های محدب می‌شود.
استفاده‌ها و کاربردها
مقدارهای مورد انتظار توان‌های "X"گشتاورهای "X"می‌نامند؛ گشتاورها نزدیک به میانگین "X" در واقع مقدارهای مورد انتظار توان‌های هستند. گشتاورهای بعضی از متغیرهای تصادفی می‌توانند برای تعیین توزیع‌هایشان از طریق تابع تولیدی گشتاوریشان استفاده شوند.
برای تخمین تجربی مقدار مورد انتظار یک متغیر تصادفی، ما به‌طور پیوسته مشاهدات متغیر را اندازه‌گیری می‌کنیم و میانگین حسابی نتایج را محاسبه می‌کنیم. اگر مقدار مورد انتظار وجود دارد، این فرایند مقدار مورد انتظار حقیقی را با یک شیوهٔ غیر تعصبی و غیر طرفدارانه را تخمین می‌زند و ویژگی به حداقل رساندن مجموع مربع‌های باقی‌مانده‌ها دارد (جمع تفاضل‌های مربع بین مشاهدات و تخمین) قانون اعداد بزرگ نشان داد که تحت شرایط نسبتاً مناسب، هنگامیکه اندازهٔ نمونه بزرگتر می‌شود واریانس این تخمین کوچکتر می‌شود.
این ویژگی در بسیار از مصارف استفاده می‌شود مانند: مسائل کلی تخمین آماری و آموزش ماشین، بریا تخمین مقدارهای (احتمالی) سود از طریق متود ها/روش‌های مونت کارلو، زیرا اکثر مقدارهای (کمیت‌های) سود می‌تواند از لحاظ امید ریاضی نوشته شوند یعنی، در اینجا تابع شاخصی برای مجموعهٔ است.
در مکانیک کلاسیک، مرکز جرم یک مفهوم مشابه امید ریاضی است. برای مثال، فرض کنید "X" یک متغیر تصادفی گسسته با مقدارهای "x" و احتمالات مرتبط "p" است، حالا یک میلهٔ بدون وزن که بر روی آن وزن‌ها در موقعیت‌های "x" در طول میله قرار گرفته‌اند و جرم آنها "p" است (که مجموع آنها یک است) نقطه که در آن میله متعادل E["X"] است.
مقدارهای مورد انتظار می‌توانند همچنین برای محاسبهٔ واریانس به وسیلهٔ فرمول‌های محاسباتی واریانس استفاده شوند.

:formula_87

یک کاربرد بسیار مهم مقدار مورد انتظار در زمینهٔ مکانیک کوانتوم است. مقدار مورد انتظار یک عملگر (یا اپراتور) مکانیکی کوانتوم formula_88 که در بردار حالت کوانتوم formula_89 کار می‌کند، به این صورت نوشته می‌شود:formula_90. . ابهام در formula_88 می‌تواند با استفاده از formula_92 محاسبه شود.
امید ماتریس‌ها
اگر formula_4 یک ماتریس formula_94 ماتریس، باشد پس مقدار مورد انتظار ماتریس به صورت ماتریس مقادیر مورد انتظار تعریف می‌شود:

:formula_95

از این در ماتریس‌های کوواریانس استفاده می‌شود
فرمول‌ها برای حالت‌های ویژه
توزیع گسسته ای که فقط مقادیر صحیح غیر منفی را می‌گیرد
وقتی که یک مقدار تصادفی فقط مقادیر داخل formula_96را می‌گیرد پس می‌توانیم از فرمول زیر برای محاسبهٔ امیدش (حتی وقتی که این امید نا متناهی باشد) استفاده کنیم:

:formula_97

اثبات:

:formula_98

با مبادلهٔ توان مجموع همان‌طور که ادعا می‌کردیم، داریم:

:formula_99

این جواب می‌تواند یک میانبر محاسباتی مفید باشد. برای مثال فرض کنید که ما یک سکه‌ای را بالا می‌اندازیم که احتمال عدد آمدن آن "p"باشد. با چند پرتاب می‌توان اولین خط‌ها (نه آنهایی که شامل خود خط هستند) را انتظار داشت؟ فرض کنید "X" این تعداد را نشان دهد. توجه کنید که ما فقط دنباله‌ها را می‌شماریم و خط‌هایی که آزمایش را پایان می‌دهند را نمی‌شماریم. ما می‌توانیم داشته باشیم که "X" = ۰. امید "X"را می‌توان از طریق محاسبه کرد. این بدین خاطر است که تعداد پرتاب‌های سکه حداقل دقیقاً "i" هستند (در زمانی که اولین پرتاب‌های "i" دنباله‌ها را بدست آورده‌است). این امر، امید یک متغیر تصادفی را با یک توزیع نمایی منطبق می‌سازد. ما از این فرمول برای تصاعد هندسی استفاده کردیم:

formula_100

توزیع پیوسته‌ای که مقادیر غیر منفی را می‌گیرد
مثل حالت گسسته‌ای که قبلاً گفته شده وقتی که یک متغیر تصادفی پیوسته‌ای مثل"X" فقط مقادیر غیر منفی را می‌گیرد پس می‌توانیم از فرمول زیر برای محاسبهٔ امیدش استفاده کنیم (حتی وقتی که امید نامتناهی باشد):
\operatorname{E}(X)=\int_0^\infty P(X \ge x)\; dx
</math>

اثبات: ابتدا فرض کنید که "X" یک چگالی برابر formula_3 داشته باشد. ما دو تکنیک ارائه می‌کنیم:
* با استفاده از انتگرال‌گیری جزئی (حالت ویژه‌ای از بخش ۱٫۴ بالا):

:formula_102

و کروشهٔ آن به صفر می‌رسد چون formula_103 به طوری که formula_104.
* با استفاده از یک مبادله در مرتبهٔ انتگرال‌گیری:

:formula_105

در حالتی که هیچ چگالی وجود نداشته باشد دیده می‌شود که:

:formula_106

تاریخ
نظریهٔ مقدار مورد انتظار در اواسط قرن هفدهم از مطالعه مشکل معروف امتیازات منشأ گرفته‌است. مشکل این بود: چگونه باید پول‌های شرط‌بندی شده را به‌طور عادلانه بین دو بازیکنی که قبل از اینکه بازی کاملاً تمام شود مجبور هستند بازی را تمام کنند تقسیم کرد؟ این مشکل قرن‌ها مورد بحث و بررسی قرار گرفت و راه حل‌ها و پیشنهادهای جنجال‌برانگیز زیادی پیشنهاد شدند. این نظریه برای اولین بار توسط یک نجیب‌زاده ی فرانسوی دومر ((de Mere در سال ۱۶۵۴ به بلیز پاسکال ارائه شد. دومر اظهار نظر کرد که این مشکل نمی‌تواند حل شود و این نشان می‌دهد ریاضی نمی‌تواند در دنیای واقعی استفاده شود و کمبود دارد. پاسکال، که یک ریاضیدان بود، برانگیخته شد و تصمیم گرفت این مشکل را برای همیشه حل کند. اولین موضوع را از طریق نامه‌های معروفی با پیر دو فرما (Pierre de fermat) در میان گذاشت. بعد از مدت زمان کوتاهی هر دوی آن‌ها به دو راه حل مجزا رسیدند. آن‌ها این مشکل را با دو راه حل محاسباتی متفاوت حل کردند، اما نتیجهٔ آن‌ها یکسان بود زیرا محاسبات شان بر اساس اصول پایه و اساسی یکسانی بود. این اصل پایه این بود که مقدار یک یود آینده باید مستقیماً با شانس به دست آوردن آن مساوی باشد. این اصل به نظر هر دوی آن‌ها کاملاً طبیعی بود. آن‌ها از اینکه به راه حل رسیده بودند بسیار خوشحال بودند و از اینرو این باعث شد آن‌ها متقاعد شوند بالاخره این مشکل را توانسته‌اند حل کنند. با این حال آن‌ها یافته‌هایشان را منتشر نکردند. آن‌ها تنها به تعدادی از دوستان مشترک محققشان در پاریس اطلاع دادند. سه سال بعد در سال ۱۶۵۷ یک ریاضی‌دان آلمانی کریستیان هیگنز، که به پاریس سفر کرده بود، یک مقاله در مورد نظریهٔ احتمال با نام (de ratiociniis in ludo ale) چاپ کرد. در آن مقاله هیگنز مسئله امتیازات را در نظر گرفته بود و یک راه حل بر اساس همان اصلی که پاسکال و فرما دنبال کرده بودند پیشنهاد کرد. او همچنین نظریه امید را با اضافه کردن قوانین مربوط به چگونه محاسبه کردن امیدها در موقعیت‌های پیچیده‌تر از مسئلهٔ اصلی، گسترش داد. هینگز در مقدمهٔ مقاله اش نوشت: باید گفته شود که بریا بعضی مواقع، بعضی از بهترین ریاضی دانان از فرانسه قبلاً به حل آن پرداخته بودند بنابراین هیچ‌کس نباید افتخار ابداع این نظریه را به من نسبت دهد. این به من تعلق ندارد. اما این دانشمندان، اگر چه هر دو یکدیگر را از طریق پرسیدن سوالات دشوار از یکدیگر در معرض آزمایش قرار داده بودند ولی روش‌هایشان را از هم پنهان کرده بودند. از اینرو من از همان اصول اولیه شروع کردم تا به حل این مسئله رسیدم و بدین دلیل غیرممکن است تأیید کنم که از همان اصول آن‌ها آغاز به کار کردم. اما در نهایت من در بسیاری از موارد بدین نتیجه رسیدم که پاسخ‌هایم با آن‌ها متفاوت هستند. از اینرو هیگنز در طی سفرش به فرانسه از اظهار نظر دومر در سال ۱۶۵۵ مطلع شد، بعداً در سال ۱۶۵۶ از طریق ارتباط با کارکاوی دریافت که روش او کاملاً همانند پاسکال است، بنابراین قبل از اینکه مقاله اش برای چاپ برود، او از ارجحیت و پیش قدمی پاسکال در این زمینه آگاه بود.
پاسکال و هیگنز هیچ‌کدام کلمهٔ امید را با مفهوم امروزی استفاده نکردند. به خصوص شانس یا امید من برای بردن هر چیزی مساوی با به دست نیاوردن آن است… اگر من انتظار دارم a یا b را به دست بیاورم، شانس بدست آوردن هر کدام از آن‌ها مساوی است، مقدار امید من (a+b)/2 است. بیش از صد سال قبل، در سال ۱۸۱۴ پیرسایمون لاپلاس مقالهٔ خود را با عنوان "Théorie analytique des probabilités" منتشر کرد، در آنجا مفهوم مقدار مورد انتظار (یا امید ریاضی) به‌طور واضح توضیح داده شد.
استفاده از حرف E به معنی مقدار مورد انتظار است که به نظریهٔ انتخاب و شانس دابیلیو. ای وایت ورت بر می‌گردد این سمبل در زمانی که بریا همهٔ نویسندگان انگلیسی، آلمانی و فرانسوی E به معنی انتظار شد.