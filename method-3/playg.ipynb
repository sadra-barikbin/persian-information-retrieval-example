{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/evaluation_IR.yml', 'r') as f:\n",
    "    dataset = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['آدولف هیتلر  شکست و مرگ',\n",
       " 'آقامحمدخان قاجار',\n",
       " 'آل افراسیاب  فرمانروایان',\n",
       " 'ابوالحسن صبا  دوران جوانی',\n",
       " 'ابومسلم خراسانی  فرمانرانی بر خراسان',\n",
       " 'اتحادیه دموکرات مسیحی آلمان  پایگاه ایدئولوژیک',\n",
       " 'ارجاسپ  در شاهنامه',\n",
       " 'استان فارس  دانشگاه\\u200cها',\n",
       " 'استاندارد طلا  استاندارد طلا و رکود شدید اقتصادی جهان',\n",
       " 'اصل موضوع انتخاب  کاربرد اصل موضوع انتخاب و قضایای هم ارز آن',\n",
       " 'اظهارنامه مالیاتی',\n",
       " 'الکترون  برهم\\u200cکنش',\n",
       " 'انرژی',\n",
       " 'انرژی پتانسیل  ویژگی\\u200cهای انرژی پتانسیل',\n",
       " 'انستیتو پاستور ایران  بخش\\u200cهای انستیتو',\n",
       " 'انیو موریکونه  زندگی شخصی و درگذشت',\n",
       " 'باشگاه فوتبال آرسنال',\n",
       " 'باشگاه فوتبال استقلال تهران  رسانه و فرهنگ عمومی',\n",
       " 'باشگاه فوتبال اینتر میلان  دوران پس از مورینیو',\n",
       " 'باشگاه فوتبال بارسلونا  رفتن راسل و آمدن بارتومئو (تاکنون-۲۰۱۴)',\n",
       " 'باشگاه فوتبال بارسلونا  رکوردها',\n",
       " 'بمب\\u200cگذاری در دفتر حزب جمهوری اسلامی  اسامی جان\\u200cباختگان',\n",
       " 'بهمن فرمان\\u200cآرا  جایزه\\u200cها و افتخارات',\n",
       " 'بیت\\u200cالعدل اعظم  گوشه\\u200cای از فعالیت\\u200cها',\n",
       " 'بیضی  تعریف بیضی با دو کانون',\n",
       " 'تاریخ افغانستان (پیش از اسلام)  شاهنشاهی کوشانیان',\n",
       " 'تاریخ گرجستان  از دوران مغول تا پایان قرن ۱۸',\n",
       " 'تعادل نش  تاریخچه',\n",
       " 'تیتانیوم دی\\u200cاکسید  فتوکاتالیست',\n",
       " 'تیم برتون  سال\\u200cهای ۱۹۸۰ تا ۱۹۹۰',\n",
       " 'تیم ملی فوتبال ایران  هماوردان',\n",
       " 'تیم ملی فوتبال ایران  ورزشگاه خانگی',\n",
       " 'تیم ملی فوتبال فرانسه  دوران امه ژاکه و زیدان',\n",
       " 'جام ملت\\u200cهای آسیا',\n",
       " 'جغرافیای جشن نوروز',\n",
       " 'جمهوری وایمار  انقلاب نوامبر (۱۹۱۸–۱۹۱۹)',\n",
       " 'جمهوری وایمار  ساختار سیاسی',\n",
       " 'جنبش سیاه\\u200cجامگان  دوره علنی',\n",
       " 'جنگ اسرائیل و لبنان (۲۰۰۶)  آغاز درگیری',\n",
       " 'جنگ کره',\n",
       " 'جو بایدن  معاونت ریاست\\u200cجمهوری (۲۰۰۹–۲۰۱۷)',\n",
       " 'جو بایدن  نقش جو بایدن در انتخابات ۲۰۱۶',\n",
       " 'جیوه  تغییر پذیری جیوه',\n",
       " 'حافظ  به\\u200cکارگیری صور خیال',\n",
       " 'حافظ  دربارهٔ حافظ',\n",
       " 'حافظه رایانه  ثبّات (رجیستر) و حافظهٔ پنهان',\n",
       " 'حاکمیت ایران بر جزایر سه\\u200cگانه  پیشینه مناقشه با استعمار بریتانیا',\n",
       " 'حداقل مربعات خطی  هندسه روش کمترین مربعات معمولی',\n",
       " 'حسن مجتبی  تدارک سپاه در مقابل معاویه',\n",
       " 'حسین واعظ کاشفی  مذهب',\n",
       " 'حقوق بشر  اعلامیه جهانی حقوق بشر',\n",
       " 'خرس  رفتارشناسی و نحوه زندگی',\n",
       " 'خرس قطبی  زیست\\u200cشناسی و رفتار',\n",
       " 'خرس قطبی  ویژگی\\u200cهای فیزیکی',\n",
       " 'دانشگاه صنعتی اصفهان  تاریخچه دانشگاه',\n",
       " 'دانشگاه علم و صنعت ایران  مدیران دانشگاه',\n",
       " 'داوود  شورش ابشالوم',\n",
       " 'دشتی (آواز)  نمونه\\u200cها',\n",
       " 'دیابت  اختلالات پیش\\u200cدیابتی',\n",
       " 'دیابت  دیابت بارداری',\n",
       " 'راه شیری  نمای ظاهری',\n",
       " 'رباعیات خیام  نسخه\\u200cهای اروپایی',\n",
       " 'رضا عطاران  سینما',\n",
       " 'رگرسیون خطی  تجزیه و تحلیل مدل',\n",
       " 'رگرسیون خطی  مدل سلسله مراتبی',\n",
       " 'ریشه دوم  خواص',\n",
       " 'زبان فارسی در هند  دیرینگی پیوند زبانی ایران و هندوستان',\n",
       " 'زرتشت  یونانیان باستان',\n",
       " 'سازمان توسعه صنعتی ملل متحد  تشکیلات و اهداف',\n",
       " 'سعید نفیسی  متون فارسی',\n",
       " 'سکته مغزی',\n",
       " 'شاه اسماعیل دوم  سیاست امنیتی و قضایی',\n",
       " 'شرکت نفت ایران و انگلیس  تاریخچه',\n",
       " 'شهرستان آباده  شاه اسماعیل سوم در آباده',\n",
       " 'شهرستان تنکابن  تاریخچه جداسازی شهرستان تنکابن',\n",
       " 'شورای نگهبان',\n",
       " 'شوقی افندی  دستاوردها',\n",
       " 'شیر و خورشید  دوران صفوی',\n",
       " 'شیر و خورشید  پس از انقلاب ۱۳۵۷',\n",
       " 'شیراز  فرودگاه',\n",
       " 'صدام حسین  پیش\\u200cزمینه کشمکش با کویت',\n",
       " 'امام علی بن موسی الرضا ع لقب رضا',\n",
       " 'علی دایی  بایرن مونیخ',\n",
       " 'علی دایی  مرحله انتخابی',\n",
       " 'علی پروین  سال ۱۳۷۲، برکناری پروین از تیم ملی',\n",
       " 'عید فطر  در مالزی',\n",
       " 'غار علی\\u200cصدر  تاریخچه',\n",
       " 'حضرت فاطمه زهرا س',\n",
       " 'فرودگاه بین\\u200cالمللی امام خمینی  پیشینه',\n",
       " 'فشار خون بالا  بحران\\u200cهای پرفشاری خون',\n",
       " 'فشار خون بالا  تشخیص',\n",
       " 'قریش (سوره)  رابطهٔ سوره\\u200cهای فیل و قریش',\n",
       " 'قضیه رمزی  اعداد رمزی',\n",
       " 'لامپ رشته\\u200cای',\n",
       " 'لطفعلی\\u200cخان زند',\n",
       " 'لطفعلی\\u200cخان زند  بعد از محاصره',\n",
       " 'لطفعلی\\u200cخان زند  توطئه\\u200cچینی در شیراز',\n",
       " 'لطفعلی\\u200cخان زند  پشت دیوارهای شیراز',\n",
       " 'ماری کوری  جایزه\\u200cهای نوبل',\n",
       " 'محاصره انطاکیه (۱۰۹۸)  بهار',\n",
       " 'محاصره انطاکیه (۱۰۹۸)  زمستان',\n",
       " 'محمد مصدق  مخالفان و منتقدان عملکرد ۲۸ ماهه دولت مصدق',\n",
       " 'مردم تالش  تاریخ مردم تالش',\n",
       " 'مریخ',\n",
       " 'معادله شرودینگر  روشی برای معادله',\n",
       " 'معادله لاپلاس  تابع گرین',\n",
       " 'مغول  تموچین یا چنگیز',\n",
       " 'مقاومت و رسانایی الکتریکی  ابر رسانا',\n",
       " 'مهندسی نرم\\u200cافزار',\n",
       " 'موسی  سرگردانی در بیابان',\n",
       " 'موسیقی راک',\n",
       " 'میخائیل گورباچف  کودتا و فروپاشی شوروی',\n",
       " 'نادرشاه  جنگ با عثمانی',\n",
       " 'نادرشاه  درگیری با تهماسب',\n",
       " 'ناسا  ایستگاه فضایی بین\\u200cالمللی (۱۹۹۸–اکنون)',\n",
       " 'نرون  کودتایی مخفیانه در برابر مادر و قتل آگریپینا',\n",
       " 'نروژ',\n",
       " 'نسبیت عام  تعریف و ویژگی\\u200cهای پایه\\u200cای',\n",
       " 'نستعلیق',\n",
       " 'نستعلیق  پیدایش و گسترش',\n",
       " 'نظریه اصل موضوعی مجموعه\\u200cها  سازگاری و عدم وابستگی در ZFC',\n",
       " 'نظریه نسبیت  نسبیت عام',\n",
       " 'نلسون ماندلا  آغاز',\n",
       " 'نهنگ قاتل  هوش',\n",
       " 'نوا (دستگاه موسیقی)  گوشه\\u200cها',\n",
       " 'نیروهای محور  اتحاد دانوب، اختلاف بر سر اتریش',\n",
       " 'هاینریش هیملر  استحکام قدرت',\n",
       " 'هاینریش هیملر  رابطه با هیتلر',\n",
       " 'هسته لینوکس',\n",
       " 'هسته لینوکس  درگیری\\u200cهای جامعه توسعه',\n",
       " 'هسته لینوکس  مدل توسعه',\n",
       " 'هم\\u200cارزی جرم و انرژی  کاربست\\u200cپذیری فرمول',\n",
       " 'هندسه جبری',\n",
       " 'هوش مصنوعی  تاریخچه',\n",
       " 'واپاشی هسته\\u200cای  پایداری و ناپایداری ایزوتوپ\\u200cها',\n",
       " 'وشمگیر  وضعیت سیاسی-اجتماعی قرن چهارم هجری',\n",
       " 'ولایت قندهار  تمدن مندیگک',\n",
       " 'ولفگانگ آمادئوس موتسارت  موتسارت در وین',\n",
       " 'ونکوور  سیستم حمل و نقل شهری',\n",
       " 'ونکوور  معماری',\n",
       " 'پروین اعتصامی',\n",
       " 'پرچم ایران  پیش از پادشاهی پهلوی\\u200cها',\n",
       " 'پیمان کیوتو  اتحادیه اروپا',\n",
       " 'چرخه آب  توصیف',\n",
       " 'چنگیز خان  کودکی',\n",
       " 'چهاردهمین دالایی لاما  اوان زندگی و سابقه',\n",
       " 'کارل مارکس  اقتصاد، تاریخ و جامعه',\n",
       " 'گرجستان  تاریخ',\n",
       " 'یانی  تأثیرپذیری\\u200cهای موسیقایی',\n",
       " 'یونسکو  فعالیت\\u200cها']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('../dataset/IR_dataset/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../dataset/IR_dataset/2048.txt',\n",
       " '../dataset/IR_dataset/2404.txt',\n",
       " '../dataset/IR_dataset/661.txt',\n",
       " '../dataset/IR_dataset/1252.txt',\n",
       " '../dataset/IR_dataset/726.txt',\n",
       " '../dataset/IR_dataset/3029.txt',\n",
       " '../dataset/IR_dataset/329.txt',\n",
       " '../dataset/IR_dataset/1481.txt',\n",
       " '../dataset/IR_dataset/1511.txt',\n",
       " '../dataset/IR_dataset/1127.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = [\n",
    "  'آ',\n",
    "  'أ',\n",
    "  'ؤ',\n",
    "  'إ',\n",
    "  'ئ',\n",
    "  'ا',\n",
    "  'ب',\n",
    "  'ة',\n",
    "  'ت',\n",
    "  'ث',\n",
    "  'ج',\n",
    "  'ح',\n",
    "  'خ',\n",
    "  'د',\n",
    "  'ذ',\n",
    "  'ر',\n",
    "  'ز',\n",
    "  'س',\n",
    "  'ش',\n",
    "  'ص',\n",
    "  'ض',\n",
    "  'ط',\n",
    "  'ظ',\n",
    "  'ع',\n",
    "  'غ',\n",
    "  'ف',\n",
    "  'ق',\n",
    "  'ك',\n",
    "  'ل',\n",
    "  'م',\n",
    "  'ن',\n",
    "  'ه',\n",
    "  'و',\n",
    "  'ى',\n",
    "  'ي',\n",
    "  '٠',\n",
    "  '١',\n",
    "  '٢',\n",
    "  '٣',\n",
    "  '٤',\n",
    "  '٥',\n",
    "  '٦',\n",
    "  '٧',\n",
    "  '٨',\n",
    "  '٩',\n",
    "  'چ',\n",
    "  'ژ',\n",
    "  'ک',\n",
    "  'گ',\n",
    "  'ھ',\n",
    "  'ی',\n",
    "  '۰',\n",
    "  '۱',\n",
    "  '۲',\n",
    "  '۳',\n",
    "  '۴',\n",
    "  '۵',\n",
    "  '۶',\n",
    "  '۷',\n",
    "  '۸',\n",
    "  '۹',\n",
    "#   '\\u200c',\n",
    "  '\\u200d',\n",
    "  '\\u200e',\n",
    "  '\\u200f',\n",
    "  'پ',\n",
    "  'ﭼ',\n",
    "  'ﯽ',\n",
    "  'ﯾ',\n",
    "  'ﯿ',\n",
    "  'ﷲ',\n",
    "  'ﺄ',\n",
    "  'ﺆ',\n",
    "  'ﺋ',\n",
    "  'ﺎ',\n",
    "  'ﺑ',\n",
    "  'ﺔ',\n",
    "  'ﺗ',\n",
    "  'ﺘ',\n",
    "  'ﺧ',\n",
    "  'ﺪ',\n",
    "  'ﺮ',\n",
    "  'ﺳ',\n",
    "  'ﺴ',\n",
    "  'ﺿ',\n",
    "  'ﻋ',\n",
    "  'ﻌ',\n",
    "  'ﻗ',\n",
    "  'ﻠ',\n",
    "  'ﻣ',\n",
    "  'ﻨ',\n",
    "  'ﻼ',\n",
    "  '￼']\n",
    "\n",
    "trans_chars = [\n",
    "  'ً',\n",
    "  'ٌ',\n",
    "  'ٍ',\n",
    "  'َ',\n",
    "  'ُ',\n",
    "  'ِ',\n",
    "  'ّ',\n",
    "  'ْ',\n",
    "  'ٓ',\n",
    "  'ٔ',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "۱۲۳۴۵ ش یب طظ ۳۴۲۲ ۶۷\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['۱۲۳۴۵', 'ش یب طظ', '۳۴۲۲', '', '۶۷']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hazm import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "x = normalizer.normalize(\"12345 ش یب طظ 3422 67\")\n",
    "print(x)\n",
    "[a.strip() for a in re.split(\"([۰-۹]+)\", x) if a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "for file in files:\n",
    "    with open(file) as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = normalizer.normalize(line)\n",
    "            line = ' '.join([a.strip() for a in re.split(\"([۰-۹]+)\", line) if a])\n",
    "            line = re.sub('[' + ''.join(trans_chars) + ']', '', line)\n",
    "            line = re.sub('[^' + ''.join(allowed_chars) + ']', ' ', line)\n",
    "#             line = re.sub('ئ', 'ی', line)\n",
    "            words.update(nltk.tokenize.word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58294,\n",
       " ['آ',\n",
       "  'آآآن',\n",
       "  'آآی',\n",
       "  'آئتیوس',\n",
       "  'آئدیلس',\n",
       "  'آئرا',\n",
       "  'آئلیوس',\n",
       "  'آئه',\n",
       "  'آئودا',\n",
       "  'آئورا',\n",
       "  'آئوراهایی',\n",
       "  'آئورت',\n",
       "  'آئورنوس',\n",
       "  'آئوسان',\n",
       "  'آئولوس',\n",
       "  'آئیم',\n",
       "  'آئین',\n",
       "  'آئینه',\n",
       "  'آئینی',\n",
       "  'آالیا'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), sorted(words)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92,\n",
       " [' ',\n",
       "  'آ',\n",
       "  'أ',\n",
       "  'ؤ',\n",
       "  'إ',\n",
       "  'ئ',\n",
       "  'ا',\n",
       "  'ب',\n",
       "  'ة',\n",
       "  'ت',\n",
       "  'ث',\n",
       "  'ج',\n",
       "  'ح',\n",
       "  'خ',\n",
       "  'د',\n",
       "  'ذ',\n",
       "  'ر',\n",
       "  'ز',\n",
       "  'س',\n",
       "  'ش',\n",
       "  'ص',\n",
       "  'ض',\n",
       "  'ط',\n",
       "  'ظ',\n",
       "  'ع',\n",
       "  'غ',\n",
       "  'ف',\n",
       "  'ق',\n",
       "  'ل',\n",
       "  'م',\n",
       "  'ن',\n",
       "  'ه',\n",
       "  'و',\n",
       "  'ى',\n",
       "  '٠',\n",
       "  '١',\n",
       "  '٢',\n",
       "  '٣',\n",
       "  '٤',\n",
       "  '٥',\n",
       "  '٦',\n",
       "  '٧',\n",
       "  '٨',\n",
       "  '٩',\n",
       "  'پ',\n",
       "  'چ',\n",
       "  'ژ',\n",
       "  'ک',\n",
       "  'گ',\n",
       "  'ھ',\n",
       "  'ی',\n",
       "  '۰',\n",
       "  '۱',\n",
       "  '۲',\n",
       "  '۳',\n",
       "  '۴',\n",
       "  '۵',\n",
       "  '۶',\n",
       "  '۷',\n",
       "  '۸',\n",
       "  '۹',\n",
       "  '\\u200c',\n",
       "  '\\u200d',\n",
       "  '\\u200e',\n",
       "  '\\u200f',\n",
       "  'ﭼ',\n",
       "  'ﯽ',\n",
       "  'ﯾ',\n",
       "  'ﯿ',\n",
       "  'ﷲ',\n",
       "  'ﺄ',\n",
       "  'ﺆ',\n",
       "  'ﺋ',\n",
       "  'ﺎ',\n",
       "  'ﺑ',\n",
       "  'ﺔ',\n",
       "  'ﺗ',\n",
       "  'ﺘ',\n",
       "  'ﺧ',\n",
       "  'ﺪ',\n",
       "  'ﺮ',\n",
       "  'ﺳ',\n",
       "  'ﺴ',\n",
       "  'ﺿ',\n",
       "  'ﻋ',\n",
       "  'ﻌ',\n",
       "  'ﻗ',\n",
       "  'ﻠ',\n",
       "  'ﻣ',\n",
       "  'ﻨ',\n",
       "  'ﻼ',\n",
       "  '￼'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars), sorted(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('../dataset/word2vec.model-skipgram-size=200-window=5.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_word2vec_format('/tmp/word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "vectors  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/word2vec.txt\") as fp:\n",
    "    for i, line in enumerate(fp):\n",
    "        if i == 0:\n",
    "            print(line)\n",
    "            continue\n",
    "        spls = line.split()\n",
    "        word = spls[0]\n",
    "        vector = [float(s) for s in spls[1:201]]\n",
    "        vocab.append(word)\n",
    "        vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"w2v/word2vec.npy\", array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240547, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w2v/vocab.txt\", 'w') as fw:\n",
    "    for w in vocab:\n",
    "        fw.write(w + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "word2vec = np.load(\"w2v/word2vec.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w2v/vocab.txt') as fp:\n",
    "    vocab = [l.strip() for l in fp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['در',\n",
       " 'و',\n",
       " '<NUM>',\n",
       " 'به',\n",
       " 'از',\n",
       " 'که',\n",
       " 'است',\n",
       " 'این',\n",
       " 'را',\n",
       " 'با',\n",
       " 'یک',\n",
       " 'سال',\n",
       " 'آن',\n",
       " 'برای',\n",
       " 'شد',\n",
       " 'بود',\n",
       " 'ایران',\n",
       " 'دارد',\n",
       " 'او',\n",
       " 'بر']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240547"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13048,\n",
       " ['اندوکاردیوم',\n",
       "  'اولگرن',\n",
       "  'اینداستوریال',\n",
       "  'سیاهمی',\n",
       "  'پادهمانندی',\n",
       "  'وتیولا',\n",
       "  'دونید',\n",
       "  'کمبی',\n",
       "  'افروزند',\n",
       "  'رایشسکانزلر',\n",
       "  'خالقزیمان',\n",
       "  'جاندارپنداری',\n",
       "  'یادین',\n",
       "  'چوودورها',\n",
       "  'کارولنکو',\n",
       "  'کشفیاتشان',\n",
       "  '۱۲۲۴',\n",
       "  'خودالیور',\n",
       "  'زداید',\n",
       "  '۱۶۱۹',\n",
       "  'والایمن',\n",
       "  'والترفیت',\n",
       "  'فراستر',\n",
       "  '۳۹۴۳',\n",
       "  '۱۰۸۵',\n",
       "  'دورانشان',\n",
       "  'همة',\n",
       "  'جامفل',\n",
       "  'یوتروپیوس',\n",
       "  '۱۲۹۹',\n",
       "  '۲۰۲۸',\n",
       "  'فیچمن',\n",
       "  '۲۱۲۸۴',\n",
       "  'ایرانشهریان',\n",
       "  '۴۱۹',\n",
       "  'آرتیمیو',\n",
       "  '۸۵',\n",
       "  '۶۵۴',\n",
       "  'میرشایمر',\n",
       "  'محدودترشد',\n",
       "  'ایکمو',\n",
       "  'جونگوا',\n",
       "  'تسوپفنر',\n",
       "  'درازاندامی',\n",
       "  'اى',\n",
       "  'مأمورهای',\n",
       "  'بزیمنسکی',\n",
       "  'هیترا',\n",
       "  'بیندوآلتوویتی',\n",
       "  'وسرور',\n",
       "  'بغدادنامه',\n",
       "  'لبرت',\n",
       "  '١٨٤٢',\n",
       "  'فتواهایش',\n",
       "  'وحوادث',\n",
       "  '۲۴۱',\n",
       "  'باداباد',\n",
       "  'تأملاتی',\n",
       "  '۲۴۰۰',\n",
       "  'نیوزپیپرز',\n",
       "  '۶۲',\n",
       "  'وسیکوزیته',\n",
       "  'عادتشان',\n",
       "  'سیکسیم',\n",
       "  'بمعلوم',\n",
       "  'نیته',\n",
       "  'خووان',\n",
       "  'ذوالیسار',\n",
       "  'نیژنا',\n",
       "  'پایقلی',\n",
       "  'هموگلوبینوپاتی',\n",
       "  'زردلیمه',\n",
       "  '۰۰۰',\n",
       "  'صلوة',\n",
       "  'رپرتوارهایی',\n",
       "  'درتحویل',\n",
       "  'وأشعه',\n",
       "  'آلونسانفان',\n",
       "  'دمونک',\n",
       "  'الدرامین',\n",
       "  '۱۹۳۳',\n",
       "  '۱۸۴۳',\n",
       "  'بایتموس',\n",
       "  'سارجلو',\n",
       "  'إله',\n",
       "  'الموتیان',\n",
       "  '۴۰۱',\n",
       "  'پیروزگرد',\n",
       "  'اورنینگی',\n",
       "  'شهها',\n",
       "  'پلمه',\n",
       "  'خرن',\n",
       "  'ابرقباد',\n",
       "  'سوجورنر',\n",
       "  'رولوایس',\n",
       "  'هرکولیها',\n",
       "  'خطریست',\n",
       "  'کنیزش',\n",
       "  'ناصافیها',\n",
       "  'ارونگ',\n",
       "  'برناد',\n",
       "  '۱۵۱۵',\n",
       "  'غیرهمروند',\n",
       "  'ساسانیاندر',\n",
       "  'سلتن',\n",
       "  'درچاه',\n",
       "  'پادرنگ',\n",
       "  '۱۵۳۲',\n",
       "  'لاباشی',\n",
       "  'ازمثال',\n",
       "  'سدمنجیل',\n",
       "  'کینگزوی',\n",
       "  'ساسمایر',\n",
       "  'برخواهم',\n",
       "  'چورووک',\n",
       "  'برنامگی',\n",
       "  'فایتویل',\n",
       "  'چرویک',\n",
       "  'سالگان',\n",
       "  'وپرکار',\n",
       "  'طوفآنهای',\n",
       "  '۲۸۴',\n",
       "  '۳۳۳۶',\n",
       "  'فیمه',\n",
       "  'خارجشان',\n",
       "  'مرمرماهی',\n",
       "  'تیونزاستور',\n",
       "  'آدناوئر',\n",
       "  'رواجینی',\n",
       "  'چوبسرخ',\n",
       "  'شامبلن',\n",
       "  'آقن',\n",
       "  '۱۳۱۳',\n",
       "  'تومارهای',\n",
       "  'رافینی',\n",
       "  'رستان',\n",
       "  'جایگزی',\n",
       "  'هیچمن',\n",
       "  'غتاب',\n",
       "  'بگریزاند',\n",
       "  'بهزار',\n",
       "  '۲۰۱۲',\n",
       "  '۲۱۱۲',\n",
       "  'خودزنیهای',\n",
       "  'کوازارهایی',\n",
       "  'زنکوئین',\n",
       "  'الحسینیة',\n",
       "  'فلرات',\n",
       "  'شکرفروش',\n",
       "  'روریز',\n",
       "  '۱۸۶۲',\n",
       "  'سالگردش',\n",
       "  'سرکوزیس',\n",
       "  'باملاحظه',\n",
       "  'فولبرت',\n",
       "  'اکهارد',\n",
       "  'آگندیکوم',\n",
       "  'وانفس',\n",
       "  '۱۵۹۰',\n",
       "  'زرندار',\n",
       "  'گوتنگ',\n",
       "  '۱۹۶۷',\n",
       "  'دوردوزی',\n",
       "  '۷',\n",
       "  '۱۴۶۴',\n",
       "  'دیوارگان',\n",
       "  '۱۷۶۴',\n",
       "  'فدارالیست',\n",
       "  'سمیونویچ',\n",
       "  'رکسنا',\n",
       "  'هرسوی',\n",
       "  '۱۳۷',\n",
       "  'ترامپر',\n",
       "  'یأس',\n",
       "  'قشار',\n",
       "  'پورنواش',\n",
       "  'اوبرلیگای',\n",
       "  'خاشقچی',\n",
       "  'عربیستی',\n",
       "  'میوها',\n",
       "  '۳۶۷',\n",
       "  'سانتیاگودر',\n",
       "  'ولوسنوس',\n",
       "  'میراکننده',\n",
       "  'پاچن',\n",
       "  'فرسکوهایی',\n",
       "  'غیرتوحیدی',\n",
       "  'اوروند',\n",
       "  'بیگلربیگیگری',\n",
       "  '۴۳۸',\n",
       "  'انوارش',\n",
       "  '۱۳۱۶',\n",
       "  'کلسترین',\n",
       "  '۳۶۳',\n",
       "  '۱۳۸۰۸۸۴',\n",
       "  '۵۳۹',\n",
       "  'میسنن',\n",
       "  'فرمانراویان',\n",
       "  'الواقعة',\n",
       "  'سیشلز'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "diff = words.difference(set(vocab))\n",
    "len(diff), sample(sorted(diff), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab = ['[PAD]', '[UNK]'] + list(words)\n",
    "vocab_r = {k:i for i,k in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word2vec = np.empty((len(new_vocab), 200), dtype=np.float64)\n",
    "new_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(new_vocab):\n",
    "    if w in vocab_r:\n",
    "        new_word2vec[i] = word2vec[vocab_r[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58296"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.06990954,  0.09599504, -0.0662043 , ..., -0.08994203,\n",
       "        -0.01352931,  0.28489596],\n",
       "       ...,\n",
       "       [ 0.05872402,  0.2257852 , -0.17468338, ..., -0.19150834,\n",
       "         0.6951406 ,  0.3027547 ],\n",
       "       [-0.10890698,  0.04909624, -0.08415384, ...,  0.01184934,\n",
       "         0.05856253,  0.09969602],\n",
       "       [-0.3580857 , -0.07599198,  0.13436021, ..., -0.02403071,\n",
       "        -0.2403924 ,  0.11183459]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w2v/vocab3.txt', 'w') as fw:\n",
    "    for w in new_vocab:\n",
    "        fw.write(w + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"w2v/word2vec3.npy\", new_word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('pos/words.txt') as fp:\n",
    "    words_all = [line.strip() for line in fp.readlines()]\n",
    "word2int = {k:i for i, k in enumerate(words_all)}\n",
    "VOCAB_SIZE = len(word2int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3535"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int['آب\\u200cها']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('pos/tags.txt') as fp:\n",
    "    tags_all = [line.strip() for line in fp.readlines()]\n",
    "tag2int = {k:i for i, k in enumerate(tags_all)}\n",
    "TAGS_NO = len(tag2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "pos_tagger = load_model('models/pos_lstm_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 100)           7840700   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 50, 160)          115840    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 50, 34)           5474      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,962,014\n",
      "Trainable params: 7,962,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pos_tagger.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "def encode_text(text):\n",
    "    text = re.sub('[' + ''.join(trans_chars) + ']', '', text)\n",
    "    text = re.sub('[^' + ''.join(allowed_chars) + ']', ' ', text)\n",
    "    text = re.sub('ئ', 'ی', text)\n",
    "    text = re.sub('ء', '', text)\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for doc in files:\n",
    "    with open(doc) as fp:\n",
    "        text = fp.read()\n",
    "        text = re.sub('\\n', '', text)\n",
    "        tokens = encode_text(text)\n",
    "        corpus.append(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3258, 60732)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_words_r = {k:i for i, k in enumerate(vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30680919856295225"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, tfidf_words_r['پودر']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "\n",
    "save_npz(\"tfidf/tfidf.npz\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf/words.txt', 'w') as fw:\n",
    "    for w in vectorizer.get_feature_names():\n",
    "        fw.write(w + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('docs.txt', 'w') as fw:\n",
    "    for doc in files:\n",
    "        fw.write(doc + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
